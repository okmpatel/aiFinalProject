{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1901488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: imports\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe9e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell 2: connect 4 definitions and minimax agent\n",
    "class Connect4:\n",
    "    def __init__(self, rows=6, cols=7, connect=4):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.connect = connect\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.rows, self.cols), dtype=int)\n",
    "        self.current_player = 1  # 1 = X, -1 = O\n",
    "        self.last_move = None\n",
    "        self.done = False\n",
    "        self.winner = None\n",
    "        return self.board.copy()\n",
    "\n",
    "    def valid_actions(self):\n",
    "        return [c for c in range(self.cols) if self.board[0, c] == 0]\n",
    "\n",
    "    def step(self, action):\n",
    "        if action not in self.valid_actions():\n",
    "            raise ValueError(\"Invalid action\")\n",
    "\n",
    "        # drop piece\n",
    "        for r in range(self.rows - 1, -1, -1):\n",
    "            if self.board[r, action] == 0:\n",
    "                self.board[r, action] = self.current_player\n",
    "                self.last_move = (r, action)\n",
    "                break\n",
    "\n",
    "        winner = check_winner(self.board, self.connect, self.last_move)\n",
    "        if winner is not None:\n",
    "            self.done = True\n",
    "            self.winner = winner\n",
    "            reward = 1 if winner == self.current_player else -1\n",
    "        elif np.all(self.board != 0):\n",
    "            self.done = True\n",
    "            self.winner = 0\n",
    "            reward = 0\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "        if not self.done:\n",
    "            self.current_player *= -1\n",
    "\n",
    "        return self.board.copy(), reward, self.done, {}\n",
    "\n",
    "    def render(self):\n",
    "        sym = {1: 'X', -1: 'O', 0: '.'}\n",
    "        for r in range(self.rows):\n",
    "            print(\" \".join(sym[int(x)] for x in self.board[r]))\n",
    "        print(\" \".join(str(i) for i in range(self.cols)))\n",
    "        print()\n",
    "\n",
    "def check_winner(board, connect=4, last_move=None):\n",
    "    rows, cols = board.shape\n",
    "\n",
    "    if last_move is not None:\n",
    "        r0, c0 = last_move\n",
    "        player = board[r0, c0]\n",
    "        if player == 0:\n",
    "            return None\n",
    "\n",
    "        dirs = [(1,0), (0,1), (1,1), (-1,1)]\n",
    "        for dr, dc in dirs:\n",
    "            count = 1\n",
    "\n",
    "            rr, cc = r0 + dr, c0 + dc\n",
    "            while 0 <= rr < rows and 0 <= cc < cols and board[rr,cc] == player:\n",
    "                count += 1\n",
    "                rr += dr; cc += dc\n",
    "\n",
    "            rr, cc = r0 - dr, c0 - dc\n",
    "            while 0 <= rr < rows and 0 <= cc < cols and board[rr,cc] == player:\n",
    "                count += 1\n",
    "                rr -= dr; cc -= dc\n",
    "\n",
    "            if count >= connect:\n",
    "                return player\n",
    "\n",
    "        return None\n",
    "\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if board[r,c] == 0:\n",
    "                continue\n",
    "            player = board[r,c]\n",
    "            for dr, dc in [(1,0),(0,1),(1,1),(-1,1)]:\n",
    "                cnt = 0\n",
    "                rr, cc = r, c\n",
    "                while 0 <= rr < rows and 0 <= cc < cols and board[rr,cc] == player:\n",
    "                    cnt += 1\n",
    "                    rr += dr; cc += dc\n",
    "                if cnt >= connect:\n",
    "                    return player\n",
    "    return None\n",
    "\n",
    "def heuristic_evaluate(board, player):\n",
    "    rows, cols = board.shape\n",
    "    opponent = -player\n",
    "\n",
    "    SCORE = {4: 100000, 3: 100, 2: 10}\n",
    "    total = 0\n",
    "\n",
    "    def score_window(window):\n",
    "        s = 0\n",
    "        cnt_p = np.count_nonzero(window == player)\n",
    "        cnt_o = np.count_nonzero(window == opponent)\n",
    "        cnt_e = np.count_nonzero(window == 0)\n",
    "\n",
    "        if cnt_p == 4:\n",
    "            s += SCORE[4]\n",
    "        elif cnt_p == 3 and cnt_e == 1:\n",
    "            s += SCORE[3]\n",
    "        elif cnt_p == 2 and cnt_e == 2:\n",
    "            s += SCORE[2]\n",
    "\n",
    "        if cnt_o == 4:\n",
    "            s -= SCORE[4]\n",
    "        elif cnt_o == 3 and cnt_e == 1:\n",
    "            s -= SCORE[3]*0.9\n",
    "        elif cnt_o == 2 and cnt_e == 2:\n",
    "            s -= SCORE[2]*0.5\n",
    "\n",
    "        return s\n",
    "\n",
    "    # horizontal\n",
    "    for r in range(rows):\n",
    "        for c in range(cols-3):\n",
    "            window = board[r, c:c+4]\n",
    "            total += score_window(window)\n",
    "\n",
    "    # vertical\n",
    "    for c in range(cols):\n",
    "        for r in range(rows-3):\n",
    "            window = board[r:r+4, c]\n",
    "            total += score_window(window)\n",
    "\n",
    "    # diag down-right\n",
    "    for r in range(rows-3):\n",
    "        for c in range(cols-3):\n",
    "            window = np.array([board[r+i, c+i] for i in range(4)])\n",
    "            total += score_window(window)\n",
    "\n",
    "    # diag up-right\n",
    "    for r in range(3, rows):\n",
    "        for c in range(cols-3):\n",
    "            window = np.array([board[r-i, c+i] for i in range(4)])\n",
    "            total += score_window(window)\n",
    "\n",
    "    # center column preference\n",
    "    center = cols // 2\n",
    "    total += np.count_nonzero(board[:, center] == player) * 3\n",
    "\n",
    "    return total\n",
    "\n",
    "def minimax_ab(board, depth, alpha, beta, maximizing, player_to_move, env):\n",
    "    w = check_winner(board, env.connect, last_move=None)\n",
    "    if w is not None:\n",
    "        return (1e9 if w == 1 else -1e9), None\n",
    "    if np.all(board != 0):\n",
    "        return 0, None\n",
    "    if depth == 0:\n",
    "        return heuristic_evaluate(board, player_to_move), None\n",
    "\n",
    "    valid_moves = [c for c in range(env.cols) if board[0, c] == 0]\n",
    "    valid_moves.sort(key=lambda c: -abs(c - env.cols//2))  # center-first move ordering\n",
    "\n",
    "    best_move = None\n",
    "\n",
    "    if maximizing:\n",
    "        value = -math.inf\n",
    "        for col in valid_moves:\n",
    "            new_board = board.copy()\n",
    "            for r in range(env.rows-1, -1, -1):\n",
    "                if new_board[r, col] == 0:\n",
    "                    new_board[r, col] = player_to_move\n",
    "                    last_r = r\n",
    "                    break\n",
    "\n",
    "            w = check_winner(new_board, env.connect, last_move=(last_r, col))\n",
    "            if w is not None:\n",
    "                v = 1e9\n",
    "            else:\n",
    "                v, _ = minimax_ab(new_board, depth-1, alpha, beta, False, -player_to_move, env)\n",
    "\n",
    "            if v > value:\n",
    "                value = v\n",
    "                best_move = col\n",
    "\n",
    "            alpha = max(alpha, value)\n",
    "            if alpha >= beta:\n",
    "                break\n",
    "\n",
    "        return value, best_move\n",
    "\n",
    "    else:\n",
    "        value = math.inf\n",
    "        for col in valid_moves:\n",
    "            new_board = board.copy()\n",
    "            for r in range(env.rows-1, -1, -1):\n",
    "                if new_board[r, col] == 0:\n",
    "                    new_board[r, col] = player_to_move\n",
    "                    last_r = r\n",
    "                    break\n",
    "\n",
    "            w = check_winner(new_board, env.connect, last_move=(last_r, col))\n",
    "            if w is not None:\n",
    "                v = -1e9\n",
    "            else:\n",
    "                v, _ = minimax_ab(new_board, depth-1, alpha, beta, True, -player_to_move, env)\n",
    "\n",
    "            if v < value:\n",
    "                value = v\n",
    "                best_move = col\n",
    "\n",
    "            beta = min(beta, value)\n",
    "            if alpha >= beta:\n",
    "                break\n",
    "\n",
    "        return value, best_move\n",
    "    \n",
    "def minimax_agent(env, depth=4):\n",
    "    board = env.board.copy()\n",
    "    player = env.current_player\n",
    "    value, action = minimax_ab(board, depth, -math.inf, math.inf, True, player, env)\n",
    "    if action is None:\n",
    "        return random.choice(env.valid_actions())\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Connect Four\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "X . . . . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "AI thinking...\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "X . . O . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "X . X O . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "AI thinking...\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . O . . .\n",
      "X . X O . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . X . . .\n",
      ". . . O . . .\n",
      "X . X O . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "AI thinking...\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . X . . .\n",
      ". . O O . . .\n",
      "X . X O . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . X . . .\n",
      "X . O O . . .\n",
      "X . X O . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "AI thinking...\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "O . . X . . .\n",
      "X . O O . . .\n",
      "X . X O . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "O . X X . . .\n",
      "X . O O . . .\n",
      "X . X O . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "AI thinking...\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . O . . .\n",
      "O . X X . . .\n",
      "X . O O . . .\n",
      "X . X O . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . O . . .\n",
      "O . X X . . .\n",
      "X . O O . . .\n",
      "X . X O . . X\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "AI thinking...\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . O O . . .\n",
      "O . X X . . .\n",
      "X . O O . . .\n",
      "X . X O . . X\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "Enter a valid integer column.\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . O O . . .\n",
      "O . X X . . .\n",
      "X . O O . . X\n",
      "X . X O . . X\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "AI thinking...\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "O . O O . . .\n",
      "O . X X . . .\n",
      "X . O O . . X\n",
      "X . X O . . X\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "O . O O . . .\n",
      "O . X X . . X\n",
      "X . O O . . X\n",
      "X . X O . . X\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "AI thinking...\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "O . O O . . O\n",
      "O . X X . . X\n",
      "X . O O . . X\n",
      "X . X O . . X\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "O . O O . . O\n",
      "O . X X . . X\n",
      "X . O O . . X\n",
      "X . X O X . X\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "AI thinking...\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "O . O O . . O\n",
      "O . X X . . X\n",
      "X . O O O . X\n",
      "X . X O X . X\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "O . O O . . O\n",
      "O . X X X . X\n",
      "X . O O O . X\n",
      "X . X O X . X\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "AI thinking...\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "O . O O . . O\n",
      "O . X X X . X\n",
      "X . O O O . X\n",
      "X O X O X . X\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "O . O O . . O\n",
      "O . X X X . X\n",
      "X X O O O . X\n",
      "X O X O X . X\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "AI thinking...\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "O . O O . . O\n",
      "O O X X X . X\n",
      "X X O O O . X\n",
      "X O X O X . X\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "AI wins!\n"
     ]
    }
   ],
   "source": [
    "#Cell 3: game loop human vs AI(minimax)\n",
    "env = Connect4()\n",
    "game_over = False\n",
    "\n",
    "print(\"Starting Connect Four\")\n",
    "env.render()\n",
    "\n",
    "# 0 = Human, 1 = AI\n",
    "turn = 0\n",
    "\n",
    "while not game_over:\n",
    "\n",
    "    if turn == 0:\n",
    "        # Human move\n",
    "        valid = env.valid_actions()\n",
    "        col = None\n",
    "        while col not in valid:\n",
    "            try:\n",
    "                col_input = int(input(f\"Your move {valid}: \"))\n",
    "                if col_input in valid:\n",
    "                    col = col_input\n",
    "                else:\n",
    "                    print(\"Invalid column. Choose from\", valid)\n",
    "            except:\n",
    "                print(\"Enter a valid integer column.\")\n",
    "        \n",
    "        _, _, game_over, _ = env.step(col)\n",
    "\n",
    "        if env.winner == 1:\n",
    "            env.render()\n",
    "            print(\"You win!\")\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        # AI move using minimax\n",
    "        print(\"AI thinking...\")\n",
    "        col = minimax_agent(env, depth=4)\n",
    "        _, _, game_over, _ = env.step(col)\n",
    "\n",
    "        if env.winner == -1:\n",
    "            env.render()\n",
    "            print(\"AI wins!\")\n",
    "            break\n",
    "\n",
    "    env.render()\n",
    "    turn = 1 - turn  # switch turns\n",
    "\n",
    "    # Check draw\n",
    "    if game_over and env.winner == 0:\n",
    "        print(\"Draw!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed750bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Q-agent training…\n",
      "Episode 2500/50000 | eps=0.952 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 5000/50000 | eps=0.905 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 7500/50000 | eps=0.857 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 10000/50000 | eps=0.810 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 12500/50000 | eps=0.762 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 15000/50000 | eps=0.715 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 17500/50000 | eps=0.667 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 20000/50000 | eps=0.620 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 22500/50000 | eps=0.572 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 25000/50000 | eps=0.525 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 27500/50000 | eps=0.477 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 30000/50000 | eps=0.430 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 32500/50000 | eps=0.382 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 35000/50000 | eps=0.335 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 37500/50000 | eps=0.287 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 40000/50000 | eps=0.240 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 42500/50000 | eps=0.192 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 45000/50000 | eps=0.145 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Episode 47500/50000 | eps=0.097 | vs minimax2 (20 games): W 0 / L 20 / D 0\n",
      "Training complete.\n",
      "Q-agent ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "q_table = defaultdict(lambda: np.zeros(7, dtype=float))\n",
    "\n",
    "alpha = 0.25\n",
    "gamma = 0.99\n",
    "\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = 0.05\n",
    "epsilon_decay_steps = 50000\n",
    "\n",
    "total_episodes = 50000    # full curriculum length\n",
    "min_episodes = 20000\n",
    "\n",
    "curriculum = [\n",
    "    (\"random\", 0.25),     # 25% vs random\n",
    "    (\"minimax2\", 0.35),   # 35% vs minimax depth 2\n",
    "    (\"selfplay\", 0.40)    # final 40% self-play\n",
    "]\n",
    "\n",
    "\n",
    "def extract_features(board, player):\n",
    "    opp = -player\n",
    "    rows, cols = board.shape\n",
    "\n",
    "    def count_patterns(val, length):\n",
    "        cnt = 0\n",
    "\n",
    "        # horizontal\n",
    "        for r in range(rows):\n",
    "            for c in range(cols - 3):\n",
    "                w = list(board[r, c:c+4])\n",
    "                if w.count(val) == length and w.count(0) == (4 - length):\n",
    "                    cnt += 1\n",
    "\n",
    "        # vertical\n",
    "        for c in range(cols):\n",
    "            for r in range(rows - 3):\n",
    "                w = list(board[r:r+4, c])\n",
    "                if w.count(val) == length and w.count(0) == (4 - length):\n",
    "                    cnt += 1\n",
    "\n",
    "        # diag down-right\n",
    "        for r in range(rows - 3):\n",
    "            for c in range(cols - 3):\n",
    "                w = [board[r+i, c+i] for i in range(4)]\n",
    "                if w.count(val) == length and w.count(0) == (4 - length):\n",
    "                    cnt += 1\n",
    "\n",
    "        # diag up-right\n",
    "        for r in range(3, rows):\n",
    "            for c in range(cols - 3):\n",
    "                w = [board[r-i, c+i] for i in range(4)]\n",
    "                if w.count(val) == length and w.count(0) == (4 - length):\n",
    "                    cnt += 1\n",
    "\n",
    "        return cnt\n",
    "\n",
    "    p2 = min(count_patterns(player, 2), 4)\n",
    "    p3 = min(count_patterns(player, 3), 4)\n",
    "    o2 = min(count_patterns(opp, 2), 4)\n",
    "    o3 = min(count_patterns(opp, 3), 4)\n",
    "\n",
    "    center_col = cols // 2\n",
    "    center_ctrl = int(np.count_nonzero(board[:, center_col] == player))\n",
    "\n",
    "    valid = [1 if board[0, c] == 0 else 0 for c in range(cols)]\n",
    "    mask_thirds = (sum(valid[0:3]) > 0) * 1 + (sum(valid[2:5]) > 0) * 2 + (sum(valid[4:7]) > 0) * 4\n",
    "\n",
    "    return (p2, p3, o2, o3, min(center_ctrl, 6), mask_thirds)\n",
    "\n",
    "def state_key(board, player):\n",
    "    return (extract_features(board, player), player)\n",
    "\n",
    "def shaped_reward(board, player, base_reward):\n",
    "    p2, p3, o2, o3, center, _ = extract_features(board, player)\n",
    "\n",
    "    r = 0\n",
    "    r += 0.08 * p2\n",
    "    r += 0.35 * p3\n",
    "    r -= 0.08 * o2\n",
    "    r -= 0.6 * o3\n",
    "    r += 0.03 * center\n",
    "\n",
    "    return r + base_reward\n",
    "\n",
    "\n",
    "def choose_action(state_key, valid, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        # exploration but biased toward center\n",
    "        if random.random() < 0.7:\n",
    "            center = 3\n",
    "            return sorted(valid, key=lambda c: abs(c - center))[0]\n",
    "        return random.choice(valid)\n",
    "\n",
    "    q_vals = q_table[state_key]\n",
    "    masked = np.full_like(q_vals, -np.inf)\n",
    "    masked[valid] = q_vals[valid]\n",
    "    return int(np.argmax(masked))\n",
    "\n",
    "def evaluate_vs_minimax(depth=2, n_games=50):\n",
    "    wins = losses = draws = 0\n",
    "\n",
    "    for _ in range(n_games):\n",
    "        env = Connect4()\n",
    "        turn = random.choice([1, -1])\n",
    "        env.current_player = turn\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if env.current_player == 1:\n",
    "                col = q_agent(env)\n",
    "            else:\n",
    "                col = minimax_agent(env, depth=depth)\n",
    "\n",
    "            _, _, done, _ = env.step(col)\n",
    "\n",
    "        if env.winner == 1:\n",
    "            wins += 1\n",
    "        elif env.winner == -1:\n",
    "            losses += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "\n",
    "    return wins, losses, draws\n",
    "\n",
    "def train_q_agent(num_episodes=total_episodes, verbose=True):\n",
    "    schedule = []\n",
    "    for name, frac in curriculum:\n",
    "        count = int(frac * num_episodes)\n",
    "        schedule.extend([name] * count)\n",
    "    while len(schedule) < num_episodes:\n",
    "        schedule.append(\"selfplay\")\n",
    "\n",
    "    epsilon = epsilon_start\n",
    "    eps_decay = (epsilon_start - epsilon_end) / epsilon_decay_steps\n",
    "\n",
    "    for ep in range(num_episodes):\n",
    "        mode = schedule[ep]\n",
    "\n",
    "        env = Connect4()\n",
    "        s_key = state_key(env.board, env.current_player)\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            valid = env.valid_actions()\n",
    "\n",
    "            if env.current_player == 1:\n",
    "                action = choose_action(s_key, valid, epsilon)\n",
    "                board2, base_reward, done, _ = env.step(action)\n",
    "                shaped = shaped_reward(board2, -env.current_player, base_reward)\n",
    "\n",
    "                next_key = state_key(board2, env.current_player)\n",
    "                q_vals = q_table[s_key]\n",
    "                next_q = q_table[next_key]\n",
    "\n",
    "                target = shaped\n",
    "                if not done:\n",
    "                    target += gamma * np.max(next_q)\n",
    "\n",
    "                q_vals[action] += alpha * (target - q_vals[action])\n",
    "                s_key = next_key\n",
    "\n",
    "\n",
    "            else:\n",
    "                if mode == \"random\":\n",
    "                    opp = random.choice(valid)\n",
    "                elif mode == \"minimax2\":\n",
    "                    opp = minimax_agent(env, depth=2)\n",
    "                else:  # selfplay: opponent tries greedy\n",
    "                    qvals = q_table[state_key(env.board, env.current_player)]\n",
    "                    masked = np.full_like(qvals, -np.inf)\n",
    "                    valid2 = env.valid_actions()\n",
    "                    masked[valid2] = qvals[valid2]\n",
    "                    opp = int(np.argmax(masked))\n",
    "\n",
    "                _, _, done, _ = env.step(opp)\n",
    "                s_key = state_key(env.board, env.current_player)\n",
    "\n",
    "        # Decay epsilon\n",
    "        if ep < epsilon_decay_steps:\n",
    "            epsilon = max(epsilon_end, epsilon - eps_decay)\n",
    "        else:\n",
    "            epsilon = epsilon_end\n",
    "\n",
    "        # Progress print\n",
    "        if verbose and ep % 2500 == 0 and ep > 0:\n",
    "            w, l, d = evaluate_vs_minimax(depth=2, n_games=20)\n",
    "            print(f\"Episode {ep}/{num_episodes} | eps={epsilon:.3f} | vs minimax2 (20 games): W {w} / L {l} / D {d}\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    return q_table\n",
    "\n",
    "\n",
    "def q_agent(env):\n",
    "    s_key = state_key(env.board, env.current_player)\n",
    "    q_vals = q_table[s_key]\n",
    "    valid = env.valid_actions()\n",
    "\n",
    "    masked = np.full_like(q_vals, -np.inf)\n",
    "    masked[valid] = q_vals[valid]\n",
    "\n",
    "    best = np.flatnonzero(masked == masked.max())\n",
    "    best = sorted(best, key=lambda c: abs(c - 3))\n",
    "    return int(best[0])\n",
    "\n",
    "\n",
    "print(\"Starting Q-agent training…\")\n",
    "train_q_agent()\n",
    "print(\"Q-agent ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89e8cc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play against Q-learning AI\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . X . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . O . . .\n",
      ". . . X . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . O . . .\n",
      ". . X X . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . O . . .\n",
      ". . . O . . .\n",
      ". . X X . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . O . . .\n",
      ". . . O . . .\n",
      ". X X X . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . O . . .\n",
      ". . . O . . .\n",
      ". . . O . . .\n",
      ". X X X . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . O . . .\n",
      ". . . O . . .\n",
      ". . . O . . .\n",
      "X X X X . . .\n",
      "0 1 2 3 4 5 6\n",
      "\n",
      "Human wins!\n"
     ]
    }
   ],
   "source": [
    "#Cell 5: game loop human vs Ai(q-learning)\n",
    "env = Connect4()\n",
    "game_over = False\n",
    "turn = 0  # 0 = human, 1 = Q-learning AI\n",
    "\n",
    "print(\"Play against Q-learning AI\")\n",
    "env.render()\n",
    "\n",
    "while not game_over:\n",
    "    if turn == 0:\n",
    "        # Human move\n",
    "        valid = env.valid_actions()\n",
    "        col = None\n",
    "        while col not in valid:\n",
    "            try:\n",
    "                col_input = int(input(f\"Your move {valid}: \"))\n",
    "                if col_input in valid:\n",
    "                    col = col_input\n",
    "            except:\n",
    "                pass\n",
    "        _, _, game_over, _ = env.step(col)\n",
    "\n",
    "    else:\n",
    "        # Q-learning AI move\n",
    "        col = q_agent(env)\n",
    "        _, _, game_over, _ = env.step(col)\n",
    "\n",
    "    env.render()\n",
    "    turn = 1 - turn\n",
    "\n",
    "    if game_over:\n",
    "        if env.winner == 1:\n",
    "            print(\"Human wins!\")\n",
    "        elif env.winner == -1:\n",
    "            print(\"AI wins!\")\n",
    "        else:\n",
    "            print(\"Draw!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8765cbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 games:\n",
      "AI1 wins: 1 (100.0%)\n",
      "AI2 wins: 0 (0.0%)\n",
      "Draws   : 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#cell 6: minimax vs q-learning\n",
    "num_simulations = 1  # number of games to simulate\n",
    "ai1_wins = 0\n",
    "ai2_wins = 0\n",
    "draws = 0\n",
    "\n",
    "# Optional: you can replace ai1_action and ai2_action with minimax_agent if you want a comparison\n",
    "for sim in range(num_simulations):\n",
    "    env = Connect4()\n",
    "    game_over = False\n",
    "    turn = 0  # 0 = Q-learning AI (ai1), 1 = Q-learning AI (ai2)\n",
    "\n",
    "    while not game_over:\n",
    "        if turn == 0:\n",
    "            col = minimax_agent(env)\n",
    "            _, _, game_over, _ = env.step(col)\n",
    "        else:\n",
    "            col = q_agent(env)\n",
    "            _, _, game_over, _ = env.step(col)\n",
    "\n",
    "        turn = 1 - turn\n",
    "\n",
    "    if env.winner == 1:\n",
    "        ai1_wins += 1\n",
    "    elif env.winner == -1:\n",
    "        ai2_wins += 1\n",
    "    else:\n",
    "        draws += 1\n",
    "\n",
    "print(f\"After {num_simulations} games:\")\n",
    "print(f\"AI1 wins: {ai1_wins} ({ai1_wins/num_simulations*100:.1f}%)\")\n",
    "print(f\"AI2 wins: {ai2_wins} ({ai2_wins/num_simulations*100:.1f}%)\")\n",
    "print(f\"Draws   : {draws} ({draws/num_simulations*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d75ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cell 7: plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['AI1', 'AI2', 'Draws']\n",
    "counts = [ai1_wins, ai2_wins, draws]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(labels, counts, color=['blue','red','gray'])\n",
    "plt.title('Q-learning Self-play Results')\n",
    "plt.ylabel('Number of Games Won')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
